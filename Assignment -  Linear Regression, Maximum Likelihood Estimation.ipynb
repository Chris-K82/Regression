{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "***Question 0***\n",
    "\n",
    "What is a likelihood function? Also add a formula and explain what it means.\n",
    "\n",
    "Likelihood function often simply called Likelihood. Likelihood is the probability that an event that has already occurred would yield specific outcome. Probability refers to the occurrence of the future events, while likelihood refers to as events with known outcomes. \n",
    "\n",
    "\n",
    "Formula:\n",
    "Let ‘X’ be a discrete random variable with probability function mass ‘p’ depending on a parameter ‘θ’. Then the function:\n",
    "\n",
    "$\\mathcal{L}(\\theta | x)=p_{\\theta}(x)=P_{\\theta}(X=x)$\n",
    "\n",
    "\n",
    "Considered as a function of ‘θ’ is the likelihood function, given the outcome ‘x’ of the random variable ‘X’.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Question 1***\n",
    "\n",
    "What is Maximum Likelihood estimation (MLE)? Can you give an example?\n",
    "\n",
    "Maximum likelihood estimation (MLE) is a method of estimating the parameters of a distribution by maximizing a likelihood function, so that under the assumed statistical model the observed data is most probable. \n",
    "The point in the parameter space that maximizes the likelihood function is called the maximum likelihood estimate.\n",
    "\n",
    "\n",
    "Example\n",
    "Suppose that there is a bag containing 3 balls. Each ball is either red or blue, but we have no information in addition to this. Thus, the number of blue balls ‘θ’, might be 0, 1, 2, or 3. I am allowed to choose 4 balls at random from the bag with replacement. We define the random X1, X2, X3 and X4 as follows\n",
    "\n",
    "Xi = {  1      if the ith chosen ball is blue; and\n",
    "\n",
    "       0       if the ith chosen ball is red   }\n",
    "\n",
    "Note that Xi’s are i.i.d. which means independent and identically distributed and Xi ~ Bernoulli (θ/3). After doing the experiment, it is observed that  Xi’s:\n",
    "\n",
    "\n",
    "x1= 1, x= 0, x3 = 1, x4 = 1. \n",
    "Thus, I observe 3 blue balls and 1 red ball.\n",
    "1.\tFor each possible value of ‘θ’ find the probability of the observed sample, (x1,x2,x3,x4) =  (1,0,1,1).\n",
    "2.\tFor which value of ‘θ’ is the probability of the observed sample is the largest?\n",
    "\n",
    "\n",
    "Since Xi ~ Bernoulli (θ/3), we have\n",
    "\n",
    "\n",
    "PXi(x) =   {   θ/3                   for x=1\n",
    "\n",
    "           1 – θ/3                   for x = 0}\n",
    "\n",
    "Since Xi’s are independent, the joint PMF of X1, X2, X3 and X4 can be written as\n",
    "\n",
    "Px1,x2,x3,x4(x1,x2,x3,x4)  = (θ/3). (1- θ/3) (θ/3). (θ/3)\n",
    "                                                = (θ/3)^3. (1- θ/3)\n",
    "\n",
    "Note that PMF depends on θ, so we write as Px1,x2,x3,x4(x1,x2,x3,x4; θ ).\n",
    "We obtain the values for the probability (1,0,1,1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "The probability of observed sample for θ =0 and θ =3 is zero. This makes sense because our sample included both red and blue balls. From the table we see that the probability of the observed data is maximized for θ =2. This means that the observed data is most likely to occur for θ =2. For this reason, we may choose θ ^=2 as our estimate of θ. This is called the maximum likelihood estimate (MLE) of θ.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Question 2***\n",
    "\n",
    "\n",
    "How is linear regression related to Pytorch and gradient descent?\n",
    " \n",
    "Linear regression using Pytorch\n",
    "Linear regression is a statistical method to study the relationship between two continuous variables.  Linear regression can be used using Pytorch. \n",
    "\n",
    "\n",
    "\n",
    "The basic steps involves importing necessary libraries \n",
    "\n",
    "The basic steps involves importing necessary libraries \n",
    "•\tImporting necessary libraries\n",
    "\n",
    "•\tGiving data, e.g. dependent and independent variables\n",
    "\n",
    "•\tDefining the model\n",
    "\n",
    "   1-Initializing model\n",
    "   \n",
    "   2-Declaring the forward pass\n",
    "   \n",
    "• Select optimizer and loss criteria\n",
    "\n",
    "   1-We can use loss function as MSE\n",
    "   \n",
    "   2-Also,  we can use Stochastic gradient descent as optimizer\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Question 3***\n",
    "\n",
    "Write out MSE (Mean square error) loss for linear regression. \n",
    "\n",
    "Mean Square Error is the most commonly used regression loss function. MSE is the sum of squared distances between our target variable and predicted values.\n",
    "\n",
    "$M S E=\\frac{\\sum_{i=1}^{n}\\left(y_{i}-y_{i}^{p}\\right)^{2}}{n}$\n",
    "\n",
    "\n",
    "Below is a plot of an MSE function where the true target value is 100, and the predicted values range between -10,000 to 10,000. The MSE loss (Y-axis) reaches its minimum value at prediction (X-axis) = 100. The range is 0 to ∞.\n",
    "\n",
    "![image.png](attachment:https://miro.medium.com/max/576/1*EqTaoCB1NmJnsRYEezSACA.png)\n",
    "\n",
    "Could we also use this loss for classification?\n",
    "Yes, from the basics of statistical machine learning, the loss function is the negative-log-likelihood of the model. To find best parameters, we need to minimize this NLL loss. The MSE is the NLL for linear regression model (with Gaussian likelihood). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
